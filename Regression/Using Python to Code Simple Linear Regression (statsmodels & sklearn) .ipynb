{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44db2ff",
   "metadata": {},
   "source": [
    "# <center><b>Math for Data Science</b></center>\n",
    "\n",
    "# <center><b>Simple Linear Regression</b></center>\n",
    "\n",
    "# <center><b>Coding Notes</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e848019",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b><font size=\"4\">Files needed for this presentation:</font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a4d24f",
   "metadata": {},
   "source": [
    "[**Cereals.xlsx**](https://docs.google.com/spreadsheets/d/1w46w7MoPPxKaWPcp1XHAQRD5Vh81JT57/edit?usp=share_link&ouid=117745432621363033141&rtpof=true&sd=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc157b",
   "metadata": {},
   "source": [
    "## Display multiple output in one cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4b2a876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The notebook is set up to display multiple output in one cell.\n"
     ]
    }
   ],
   "source": [
    "# set up notebook to display multiple output in one cell\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "print('The notebook is set up to display multiple output in one cell.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3a02e9",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "66d54fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcdd510",
   "metadata": {},
   "source": [
    "## Load the cereals dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12ba13df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cereals = pd.read_excel(\"Cereals.xlsx\", usecols = ['Cereal Name', 'Rating', 'Sugar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c97bd9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cereal Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Sugar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100%_Bran</td>\n",
       "      <td>68.402973</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100%_Natural_Bran</td>\n",
       "      <td>33.983679</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All-Bran</td>\n",
       "      <td>59.425505</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All-Bran_with_Extra_Fiber</td>\n",
       "      <td>93.704912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Almond_Delight</td>\n",
       "      <td>34.384843</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Cereal Name     Rating  Sugar\n",
       "0                  100%_Bran   68.402973      6\n",
       "1          100%_Natural_Bran   33.983679      8\n",
       "2                   All-Bran   59.425505      5\n",
       "3  All-Bran_with_Extra_Fiber   93.704912      0\n",
       "4             Almond_Delight   34.384843      8"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(76, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cereals.head()\n",
    "cereals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a869a098",
   "metadata": {},
   "source": [
    "## Use the statsmodels library to perform simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f064cb3",
   "metadata": {},
   "source": [
    "**Documentation:**&emsp;[**statsmodels**](https://www.statsmodels.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7c349f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "433e2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(formula = 'Rating ~ Sugar', data = cereals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3928cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6651a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Rating   R-squared:                       0.584\n",
      "Model:                            OLS   Adj. R-squared:                  0.578\n",
      "Method:                 Least Squares   F-statistic:                     103.7\n",
      "Date:                Sat, 18 Feb 2023   Prob (F-statistic):           1.01e-15\n",
      "Time:                        11:29:15   Log-Likelihood:                -275.21\n",
      "No. Observations:                  76   AIC:                             554.4\n",
      "Df Residuals:                      74   BIC:                             559.1\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     59.8530      1.998     29.964      0.000      55.873      63.833\n",
      "Sugar         -2.4614      0.242    -10.183      0.000      -2.943      -1.980\n",
      "==============================================================================\n",
      "Omnibus:                       12.448   Durbin-Watson:                   1.815\n",
      "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               14.427\n",
      "Skew:                           0.787   Prob(JB):                     0.000737\n",
      "Kurtosis:                       4.441   Cond. No.                         15.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc21da",
   "metadata": {},
   "source": [
    "## Interpret the regression output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440cfd75",
   "metadata": {},
   "source": [
    "- **LSRL Equation**: Rating = -2.4614*Sugar + 59.8530\n",
    "- **Slope interpretation**: For each additional gram of sugar, the LSRL predicts that the cereal's nutritional rating will decrease by 2.4614 points\n",
    "- **Intercept interpretation**: The LSRL predicts that a cereal with 0 grams of sugar will have a nutritional rating of 59.8530.\n",
    "- **R-squared** = 0.584 ... When using the LSRL to have grams of sugar predict a cereal's nutritional rating, 58.4% of the variation in a cereal's nutritional rating is accounted for by the number of grams of sugar in the cereal.\n",
    "- **SE(Sugar)** = 0.242 ... \"standard error of the slope\" -- Over repeated random samples, the slope of the sample regression line would typically vary by about 0.242 from the slope of the population (true) regression line for predicting nutritional rating from grams of sugar. \n",
    "- **Hypothesis (Significance) Test**:\n",
    " - Student's t Test Statistic for Sugar: t = -10.183\n",
    " - p-value for Student's t Test Statistic for Sugar: P>|t| = 0.000\n",
    " - Decision about $H_{0}$: Since the p-value, ≈ 0.000, is less than α =0.05, we should reject $H_{0}$.\n",
    " - Conclusion about $H_{a}$: There is sufficient evidence to conclude that there is a linear relationship between a cereal's nutritional rating and its sugar content.\n",
    "- **95% Confidence Interval**:\n",
    " - We are 95% confident that the interval from -2.943 to -1.980 captures the actual slope of the population regression line. That is, 95% of all possible samples of size n = 76 from this population of cereals result in an interval that captures the slope of the population (true) regression line for predicting nutritional rating from grams of sugar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f3ea5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept    59.853017\n",
      "Sugar        -2.461420\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# if you want just the parameters ... call the params attribute on the results\n",
    "\n",
    "print(results.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f01c39a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0          1\n",
      "Intercept  55.872858  63.833176\n",
      "Sugar      -2.943061  -1.979779\n"
     ]
    }
   ],
   "source": [
    "# if you want to report a confidence interval, use the conf_int method\n",
    "# ... the confidence interval identifies the possible/likely values that the estimated value can take on\n",
    " \n",
    "print(results.conf_int())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecd653b",
   "metadata": {},
   "source": [
    "## Use the sklearn library to perform simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750aa17",
   "metadata": {},
   "source": [
    "**Documentation:**&emsp;[**sklearn ... scikit-learn Machine Learning in Python**](https://scikit-learn.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2a86c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70496393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our LinearRegression object\n",
    "\n",
    "lr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e2c3d72",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 6  8  5  0  8 10 14  8  6  5 12  1  9  7 13  3  2 12 13  7  0  3 10  5\n 13 11  7 10 12 12 15  9  5  3  4 11 10 11  6  9  3  6 12  3 11 11 13  6\n  9  7  2 10 14  3  0  0  6 12  8  6  2  3  0  0  0 15  3  5  3 14  3  3\n 12  3  3  8].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-49-01d5a9c071a3>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m# this will fail because our X has only one variable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mpredicted\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcereals\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Sugar'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcereals\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Rating'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    516\u001B[0m         \u001B[0maccept_sparse\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpositive\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m'csr'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'csc'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'coo'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    517\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 518\u001B[1;33m         X, y = self._validate_data(X, y, accept_sparse=accept_sparse,\n\u001B[0m\u001B[0;32m    519\u001B[0m                                    y_numeric=True, multi_output=True)\n\u001B[0;32m    520\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    431\u001B[0m                 \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    432\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 433\u001B[1;33m                 \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_X_y\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    434\u001B[0m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    435\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m             \u001B[1;31m# extra_args > 0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m    812\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"y cannot be None\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    813\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 814\u001B[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001B[0m\u001B[0;32m    815\u001B[0m                     \u001B[0maccept_large_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maccept_large_sparse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    816\u001B[0m                     \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m             \u001B[1;31m# extra_args > 0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[0;32m    635\u001B[0m             \u001B[1;31m# If input is 1D raise error\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    636\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0marray\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 637\u001B[1;33m                 raise ValueError(\n\u001B[0m\u001B[0;32m    638\u001B[0m                     \u001B[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    639\u001B[0m                     \u001B[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Expected 2D array, got 1D array instead:\narray=[ 6  8  5  0  8 10 14  8  6  5 12  1  9  7 13  3  2 12 13  7  0  3 10  5\n 13 11  7 10 12 12 15  9  5  3  4 11 10 11  6  9  3  6 12  3 11 11 13  6\n  9  7  2 10 14  3  0  0  6 12  8  6  2  3  0  0  0 15  3  5  3 14  3  3\n 12  3  3  8].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# next, specify the predictor X, and the reponse y\n",
    "# note -- it is uppercase X and lowercase y\n",
    "# this will fail because our X has only one variable \n",
    "\n",
    "predicted = lr.fit(X = cereals['Sugar'], y = cereals['Rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcbd4d3",
   "metadata": {},
   "source": [
    "- Since **sklearn** is built to take NumPy arrays, there will be times when you have to do some data manipulations to pass your DataFrame into **sklearn** \n",
    "- The error message in the output above essentially tells us that the matrix passed is not in the correct shape.  There we need to reshape the inputs.\n",
    "- Depending on whether we have a single feature (whixh is the case above) or a single sample (i.e. multiple observations), we should specify reshape(-1, 1) or reshape(1, -1) respectively.\n",
    "- To properly reshape our data, we must use the values attribute ... when we call values on a Pandas DataFrame or Series, we get the numpy ndarray representation of the data,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4771c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fix the error above\n",
    "\n",
    "predicted = lr.fit(X = cereals['Sugar'].values.reshape(-1, 1), y = cereals['Rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c98e99",
   "metadata": {},
   "source": [
    "- Unfortunately, **sklearn** doesn't provide us with the nice summary table that **statsmodels** does,\n",
    "- To obtain the slope coefficient in sklearn, call the coef_ attribute on the fitted model.\n",
    "- To get the intercept, call the intercept_ attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "07ee5199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.46142021]\n",
      "59.85301691061821\n"
     ]
    }
   ],
   "source": [
    "print(predicted.coef_)\n",
    "print(predicted.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a4b1bccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope coefficient: [-2.46142021]\n",
      "intercept: 59.85301691061821\n"
     ]
    }
   ],
   "source": [
    "print(f'slope coefficient: {predicted.coef_}')\n",
    "print(f'intercept: {predicted.intercept_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7eb90a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
